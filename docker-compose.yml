version: '3.8'

services:
  # --- INFRASTRUCTURE (Kafka & Zookeeper) ---
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # --- BACKEND API ---
  api:
    build: 
      context: .
      dockerfile: Dockerfile_API  # Vous devrez créer ce fichier (voir plus bas)
    container_name: github_api
    ports:
      - "8000:8000"
    volumes:
      - .:/app  # Montage pour que l'API voit le modèle .pkl mis à jour par le scheduler
    command: uvicorn ProjetDB_Back.main:app --host 0.0.0.0 --port 8000 --reload
    depends_on:
      - kafka

  # --- FRONTEND STREAMLIT ---
  frontend:
    build:
      context: .
      dockerfile: Dockerfile_Front # Idem
    container_name: github_front
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://api:8000 # L'adresse de l'API dans le réseau Docker
    volumes:
      - .:/app
    command: streamlit run ProjetDB_Front/app.py
    depends_on:
      - api

  # --- ORCHESTRATEUR ---
  scheduler:
    image: python:3.11-slim
    container_name: github_scheduler
    volumes:
      - .:/app
    working_dir: /app
    # Installation des dépendances minimales pour les scripts
    command: >
      sh -c "pip install pymongo kafka-python pandas scikit-surprise requests schedule && python scheduler.py"
    depends_on:
      - kafka
      - api